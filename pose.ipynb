{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"res.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>six</th>\n",
       "      <th>seven</th>\n",
       "      <th>eight</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>98</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>98</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>97</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>105</td>\n",
       "      <td>69</td>\n",
       "      <td>94</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five  six  seven  eight  cls\n",
       "0   87   78     98    71    94  100     89     64    0\n",
       "1   83   77    101    66    88   91     82     58    0\n",
       "2   76   75     98    65    90   94     88     55    0\n",
       "3   87   78    100    70    97   94     89     73    0\n",
       "4   82   80    105    69    94   99     95     69    0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "train_features = train_data.copy()\n",
    "train_labels = train_features.pop(\"cls\")\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "test_features = test_data.copy()\n",
    "test_labels = test_features.pop(\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>six</th>\n",
       "      <th>seven</th>\n",
       "      <th>eight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>102</td>\n",
       "      <td>237</td>\n",
       "      <td>104</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>117</td>\n",
       "      <td>76</td>\n",
       "      <td>103</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>68</td>\n",
       "      <td>158</td>\n",
       "      <td>91</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>134</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>91</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>148</td>\n",
       "      <td>199</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>109</td>\n",
       "      <td>150</td>\n",
       "      <td>94</td>\n",
       "      <td>68</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "      <td>237</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     one  two  three  four  five  six  seven  eight\n",
       "0     69   28     77    72    44   80     26     51\n",
       "1     91  102    237   104    87   60     62     52\n",
       "2     77   61     59    10     1  125    155     69\n",
       "3     88   79    117    76   103   92     87     52\n",
       "4     71   56     76    68   158   91     54     48\n",
       "..   ...  ...    ...   ...   ...  ...    ...    ...\n",
       "571   75    3     60    44   134   95     84     53\n",
       "572   91  134    204    48     2   60     63     48\n",
       "573   54    2    157   148   199   95     56     63\n",
       "574   84   70     81   109   150   94     68     55\n",
       "575   71   92    237   119   124   60     65     55\n",
       "\n",
       "[576 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = train_features.values.mean(axis=0), train_features.values.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mean.shape == (8,)\n",
    "assert std.shape == (8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81.27430556  60.69618056 139.90277778  87.78819444 101.45138889\n",
      "  98.40972222  60.98611111  47.171875  ]\n",
      "[29.69119596 38.05961679 67.94310012 39.25168432 56.3846019  39.34889579\n",
      " 35.38674935 18.1955993 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{mean}\\n{std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to nparray\n",
    "num_classes = 6\n",
    "train_features = train_features.values.astype(\"float32\")\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes, dtype=\"float32\")\n",
    "test_features = test_features.values.astype(\"float32\")\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # Normalize the value first\n",
    "    x = (x - mean) / std\n",
    "    \n",
    "    # Map -1 ~ 1 to -127 ~ 127\n",
    "    x = x * 127\n",
    "    \n",
    "    # Set up the limit bound\n",
    "    x = np.where(x > 127, 127, x)\n",
    "    x = np.where(x < -128, -128, x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "train_features = normalize(train_features)\n",
    "test_features = normalize(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model define and create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# FC1\n",
    "model.add(Input(shape=(8,), dtype=tf.float32))\n",
    "model.add(Dense(64, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# FC2\n",
    "model.add(Dense(128, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# FC3\n",
    "model.add(Dense(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                512       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8192      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,246\n",
      "Trainable params: 9,862\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show your model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 20ms/step - loss: 1.6137 - accuracy: 0.3552 - val_loss: 1.6402 - val_accuracy: 0.5345\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.8205 - val_loss: 0.9720 - val_accuracy: 0.7069\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.9151 - val_loss: 0.7044 - val_accuracy: 0.7586\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.9440 - val_loss: 0.5738 - val_accuracy: 0.7931\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9807 - val_loss: 0.4996 - val_accuracy: 0.8276\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9846 - val_loss: 0.4409 - val_accuracy: 0.8621\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9846 - val_loss: 0.3870 - val_accuracy: 0.8793\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9865 - val_loss: 0.3468 - val_accuracy: 0.8966\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9826 - val_loss: 0.3093 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9884 - val_loss: 0.2720 - val_accuracy: 0.9138\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9865 - val_loss: 0.2405 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9884 - val_loss: 0.2051 - val_accuracy: 0.9310\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9884 - val_loss: 0.1798 - val_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9884 - val_loss: 0.1617 - val_accuracy: 0.9828\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9903 - val_loss: 0.1491 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9903 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9846 - val_loss: 0.1165 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9884 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9903 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9788 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9884 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9923 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9903 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9942 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9923 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9942 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9981 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9884 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9942 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9942 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9961 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9942 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9942 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9961 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9942 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9923 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9846 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9961 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9942 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9923 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9884 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9961 - val_loss: 0.0400 - val_accuracy: 0.9828\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9923 - val_loss: 0.0417 - val_accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9923 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9981 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9981 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9942 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9961 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9923 - val_loss: 0.0319 - val_accuracy: 0.9828\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9942 - val_loss: 0.0356 - val_accuracy: 0.9828\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9942 - val_loss: 0.0354 - val_accuracy: 0.9828\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9961 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9865 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9961 - val_loss: 0.0442 - val_accuracy: 0.9828\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9884 - val_loss: 0.0505 - val_accuracy: 0.9828\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.0463 - val_accuracy: 0.9828\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9942 - val_loss: 0.0431 - val_accuracy: 0.9828\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9981 - val_loss: 0.0375 - val_accuracy: 0.9828\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9865 - val_loss: 0.0331 - val_accuracy: 0.9828\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9961 - val_loss: 0.0310 - val_accuracy: 0.9828\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.0278 - val_accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.0369 - val_accuracy: 0.9828\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9961 - val_loss: 0.0889 - val_accuracy: 0.9655\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9846 - val_loss: 0.1140 - val_accuracy: 0.9655\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0853 - val_accuracy: 0.9655\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.0568 - val_accuracy: 0.9828\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0410 - val_accuracy: 0.9828\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9961 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9981 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9961 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9942 - val_loss: 0.0349 - val_accuracy: 0.9828\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 0.0347 - val_accuracy: 0.9828\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.0318 - val_accuracy: 0.9828\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.0356 - val_accuracy: 0.9828\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9942 - val_loss: 0.0328 - val_accuracy: 0.9828\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9961 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9981 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 0.0147 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172968dc448>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "# Define optimizer loss function and merics \n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# Set training\n",
    "model.fit(\n",
    "    train_features, train_labels_one_hot, \n",
    "    validation_split=0.1, batch_size=64,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020059330388903618, 1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Save weights of this model  \n",
    "model.save_weights('my_model.h5')\n",
    "\n",
    "#load weights to this TensorFlow model  \n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights of this model\n",
    "model.save(\"model_save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload and preprocess images in TFLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Convert model into TFLM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = tf.cast(test_features, tf.float32)\n",
    "tf_lite_ds = tf.data.Dataset.from_tensor_slices((test_features)).batch(1)\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tf_lite_ds.take(100):\n",
    "        yield [input_value]\n",
    "    \n",
    "converter.representative_dataset = representative_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpguc_6zzq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "converter_model = converter.convert()\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"pose.tflite\"\n",
    "converted_model_file.write_bytes(converter_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"pose.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    scale, zero_point = interpreter.get_output_details()[0][\"quantization\"]\n",
    "\n",
    "    prediction_values = []\n",
    "    \n",
    "    for test_data in test_features:\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\n",
    "        # the model's input data format.\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "        test_data = np.int8(test_data)\n",
    "        interpreter.set_tensor(input_index, test_data)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Find the letter with highest probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        result = np.argmax(output()[0])\n",
    "        prediction_values.append(result)\n",
    "    \n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_values)):\n",
    "        if prediction_values[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\n",
    "\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, keep in mind that full test dataset evaluation on int8 model may take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test set for target application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Import training and testing from dataset_buffer\n",
    "num_of_samples = 25\n",
    "random_test_features = random.sample(range(1, test_features.shape[0]), num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = open(\"generated/test_samples.cpp\", \"w\")\n",
    "\n",
    "samples_file.write(\"#include \\\"test_samples.h\\\"\\n\\n\")\n",
    "samples_file.write(\"const int kNumSamples = \" + str(num_of_samples) + \";\\n\\n\")\n",
    "\n",
    "samples = \"\" \n",
    "samples_array = \"const TestSample test_samples[kNumSamples] = {\"\n",
    "\n",
    "for sample_idx, feature_idx in enumerate(random_test_features, 1):\n",
    "    feature_arr = list(np.array(test_features[feature_idx]).astype(\"int\"))\n",
    "    var_name = \"sample\" + str(sample_idx)\n",
    "    samples += \"TestSample \" + var_name + \" = {\\n\" #+ \"[IMAGE_SIZE] = { \"\n",
    "    samples += \"\\t.label = \" + str(test_labels[feature_idx]) + \",\\n\" \n",
    "    samples += \"\\t.feature = {\\n\"\n",
    "    samples += \"\\t\\t\" + str(feature_arr)\n",
    "    samples += \"\\t}\\n};\\n\\n\"    \n",
    "    samples_array += var_name + \", \"\n",
    "    \n",
    "samples = samples.replace(\"[\", \"\")\n",
    "samples = samples.replace(\"]\", \",\\n\")\n",
    "samples_array += \"};\\n\"\n",
    "\n",
    "samples_file.write(samples);\n",
    "samples_file.write(samples_array);\n",
    "samples_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have converted a Tensorflow model into TFLM format and generated a test set for the application. Now you can copy generated files into target application of this tutorial and try it out:\n",
    "\n",
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application.\n",
    "\n",
    "* copy *generated/model.h* to *../inc* and *generated/test_samples.cc* to *../src*\n",
    "* You can start to integrate your WE-I project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
